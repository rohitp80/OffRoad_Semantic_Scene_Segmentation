{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emo457EwnHLH",
        "outputId": "cf2cd0a7-2f4c-4dd0-a4b4-b896469fce59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v_CceL8inOZi"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y torch torchvision torchaudio xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DuBO65jnZxL",
        "outputId": "164b82ac-664e-4721-de3f-8434ffec555c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (799.0 MB)\n",
            "Collecting torchvision==0.19.0\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "Collecting torchaudio==2.4.0\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: triton 3.6.0\n",
            "    Uninstalling triton-3.6.0:\n",
            "      Successfully uninstalled triton-3.6.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.10.0\n",
            "    Uninstalling torch-2.10.0:\n",
            "      Successfully uninstalled torch-2.10.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.25.0\n",
            "    Uninstalling torchvision-0.25.0:\n",
            "      Successfully uninstalled torchvision-0.25.0\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torchmetrics segmentation-models-pytorch\n",
        "# 2. Install a modern stable trio that exists in the index\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# 3. Install compatible xformers\n",
        "!pip install -q xformers==0.0.27.post2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gzq_ukg2qUIS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "3-9RZNzWYFHf",
        "outputId": "2b9a669c-b8d6-4108-9e5a-2fb6bb9c82a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== TRAINING MODEL 1/3 | SEED 42 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 179/179 [05:31<00:00,  1.85s/it, loss=0.6891]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 1.1954 | Val Loss: 0.6808 | Train IoU: 0.3899 | Val IoU: 0.3438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 179/179 [03:28<00:00,  1.16s/it, loss=0.5007]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3840850125.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3840850125.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m                         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                     )\n\u001b[0;32m--> 243\u001b[0;31m                     \u001b[0mtrain_ious\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mtrain_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3840850125.py\u001b[0m in \u001b[0;36mcompute_iou\u001b[0;34m(pred, gt, num_classes)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munion\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mious\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import os\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# ============================================================\n",
        "# CONFIG\n",
        "# ============================================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "N_ENSEMBLE = 3\n",
        "SEEDS = [42, 123, 999]\n",
        "BATCH_SIZE = 12\n",
        "W, H = 896, 504\n",
        "LR = 5e-4\n",
        "EPOCHS = 10\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/data/Offroad_Segmentation_Training_Dataset/Offroad_Segmentation_Training_Dataset\"\n",
        "TRAIN_DIR = os.path.join(BASE_PATH, \"train\")\n",
        "VAL_DIR = os.path.join(BASE_PATH, \"val\")\n",
        "\n",
        "# ============================================================\n",
        "# LOSS\n",
        "# ============================================================\n",
        "class DiceCELoss(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        ce_loss = self.ce(pred, target)\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        target_oh = F.one_hot(target, self.num_classes).permute(0,3,1,2).float()\n",
        "\n",
        "        inter = (pred * target_oh).sum((2,3))\n",
        "        union = (pred + target_oh).sum((2,3))\n",
        "        dice = 1 - (2 * inter / (union + 1e-6)).mean()\n",
        "\n",
        "        return 0.5 * ce_loss + 0.5 * dice\n",
        "\n",
        "# ============================================================\n",
        "# MASK UTILS\n",
        "# ============================================================\n",
        "value_map = {\n",
        "    0: 0, 100: 1, 200: 2, 300: 3, 500: 4,\n",
        "    550: 5, 700: 6, 800: 7, 7100: 8, 10000: 9\n",
        "}\n",
        "N_CLASSES = len(value_map)\n",
        "\n",
        "def convert_mask(mask):\n",
        "    arr = np.array(mask, dtype=np.uint16)\n",
        "    new = np.zeros_like(arr, dtype=np.uint8)\n",
        "    for k, v in value_map.items():\n",
        "        new[arr == k] = v\n",
        "    return new\n",
        "\n",
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "class MaskDataset(Dataset):\n",
        "    def __init__(self, root, h, w, train=True):\n",
        "        self.img_dir = os.path.join(root, \"Color_Images\")\n",
        "        self.mask_dir = os.path.join(root, \"Segmentation\")\n",
        "\n",
        "        if train:\n",
        "            self.tf = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.RandomRotate90(p=0.5),\n",
        "                A.ShiftScaleRotate(0.1,0.1,15,p=0.5),\n",
        "                A.Resize(h,w),\n",
        "                A.ColorJitter(0.4,0.4,0.4,0.1,p=0.8),\n",
        "                A.RandomBrightnessContrast(p=0.5),\n",
        "                A.Normalize(mean=(0.485,0.456,0.406),\n",
        "                            std=(0.229,0.224,0.225)),\n",
        "                ToTensorV2(transpose_mask=True)\n",
        "            ])\n",
        "        else:\n",
        "            self.tf = A.Compose([\n",
        "                A.Resize(h,w),\n",
        "                A.Normalize(mean=(0.485,0.456,0.406),\n",
        "                            std=(0.229,0.224,0.225)),\n",
        "                ToTensorV2(transpose_mask=True)\n",
        "            ])\n",
        "\n",
        "        self.ids = sorted(os.listdir(self.img_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        name = self.ids[i]\n",
        "        img = np.array(Image.open(os.path.join(self.img_dir, name)).convert(\"RGB\"))\n",
        "        mask = convert_mask(Image.open(os.path.join(self.mask_dir, name)))\n",
        "        aug = self.tf(image=img, mask=mask)\n",
        "        return aug[\"image\"], aug[\"mask\"].long()\n",
        "\n",
        "# ============================================================\n",
        "# MODEL\n",
        "# ============================================================\n",
        "class SegmentationHeadConvNeXt(nn.Module):\n",
        "    def __init__(self, in_c, out_c, w, h):\n",
        "        super().__init__()\n",
        "        self.w, self.h = w, h\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(in_c, 256, 7, padding=3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.GELU()\n",
        "        )\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(256,256,7,padding=3,groups=256),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(256,256,1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        self.cls = nn.Conv2d(256,out_c,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        b,n,c = x.shape\n",
        "        x = x.reshape(b,self.h,self.w,c).permute(0,3,1,2)\n",
        "        return self.cls(self.block(self.stem(x)))\n",
        "\n",
        "# ============================================================\n",
        "# METRIC\n",
        "# ============================================================\n",
        "def compute_iou(pred, gt, num_classes):\n",
        "    pred = torch.argmax(pred,1).view(-1)\n",
        "    gt = gt.view(-1)\n",
        "    ious = []\n",
        "    for c in range(num_classes):\n",
        "        inter = ((pred==c)&(gt==c)).sum().float()\n",
        "        union = ((pred==c)|(gt==c)).sum().float()\n",
        "        if union > 0:\n",
        "            ious.append((inter/union).item())\n",
        "    return np.mean(ious)\n",
        "\n",
        "# ============================================================\n",
        "# TRAIN + ENSEMBLE\n",
        "# ============================================================\n",
        "def main():\n",
        "    train_loader = DataLoader(\n",
        "        MaskDataset(TRAIN_DIR, H, W, True),\n",
        "        batch_size=BATCH_SIZE, shuffle=True, num_workers=4\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        MaskDataset(VAL_DIR, H, W, False),\n",
        "        batch_size=BATCH_SIZE, shuffle=False, num_workers=4\n",
        "    )\n",
        "\n",
        "    backbone = torch.hub.load(\n",
        "        \"facebookresearch/dinov2\",\"dinov2_vitb14\"\n",
        "    ).to(DEVICE).eval()\n",
        "\n",
        "    loss_fn = DiceCELoss(N_CLASSES).to(DEVICE)\n",
        "    ensemble = []\n",
        "\n",
        "    for idx, seed in enumerate(SEEDS):\n",
        "        print(f\"\\n===== TRAINING MODEL {idx+1}/{N_ENSEMBLE} | SEED {seed} =====\")\n",
        "        torch.manual_seed(seed); np.random.seed(seed)\n",
        "\n",
        "        model = SegmentationHeadConvNeXt(\n",
        "            768, N_CLASSES, W//14, H//14\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "        sch = optim.lr_scheduler.OneCycleLR(\n",
        "            opt, max_lr=LR,\n",
        "            steps_per_epoch=len(train_loader),\n",
        "            epochs=EPOCHS\n",
        "        )\n",
        "        scaler = GradScaler(\"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS):\n",
        "            model.train()\n",
        "            losses = []\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f\"Epoch {ep+1}/{EPOCHS}\")\n",
        "            for imgs, masks in pbar:\n",
        "                imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "                with autocast(\"cuda\"):\n",
        "                    with torch.no_grad():\n",
        "                        feat = backbone.forward_features(imgs)[\"x_norm_patchtokens\"]\n",
        "                    logits = model(feat)\n",
        "                    out = F.interpolate(logits, imgs.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "                    loss = loss_fn(out, masks)\n",
        "\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                sch.step()\n",
        "\n",
        "                losses.append(loss.item())\n",
        "                pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "            print(f\"Epoch {ep+1} | Train Loss: {np.mean(losses):.4f}\")\n",
        "\n",
        "        ensemble.append(model.eval())\n",
        "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/offroad_model_seed_{seed}.pth\")\n",
        "\n",
        "    print(\"\\n===== ENSEMBLE VALIDATION =====\")\n",
        "    ious = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in tqdm(val_loader):\n",
        "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "            logits_sum = 0\n",
        "            for model in ensemble:\n",
        "                feat = backbone.forward_features(imgs)[\"x_norm_patchtokens\"]\n",
        "                logits = model(feat)\n",
        "                logits = F.interpolate(logits, imgs.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "                logits_sum += logits\n",
        "            logits_mean = logits_sum / len(ensemble)\n",
        "            ious.append(compute_iou(logits_mean, masks, N_CLASSES))\n",
        "\n",
        "    print(f\"\\nENSEMBLE Val IoU: {np.mean(ious):.4f}\")\n",
        "    print(\"DONE.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj0WHAFtnEnD",
        "outputId": "44e8e88d-5e7d-4f04-82b7-0095cf834e25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Ensemble + TTA inference...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1004/1004 [1:39:52<00:00,  5.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TEST MEAN IoU: 0.3243\n",
            "DONE.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Segmentation Testing Script - FINAL FIXED\n",
        "- Correct mask encoding (FIXES IoU = 0)\n",
        "- Ensemble + Full TTA (8 variants)\n",
        "- Meaningful test-time graphs\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os, shutil\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# CONFIG\n",
        "# ============================================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "H, W = 504, 896\n",
        "N_CLASSES = 10\n",
        "EMBED_DIM = 768\n",
        "\n",
        "MODEL_PATHS = [\n",
        "    \"/content/drive/MyDrive/offroad_model_seed_42.pth\",\n",
        "    \"/content/drive/MyDrive/offroad_model_seed_123.pth\",\n",
        "    \"/content/drive/MyDrive/offroad_model_seed_999.pth\",\n",
        "]\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/data/Offroad_Segmentation_testImages/Offroad_Segmentation_testImages\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/test_results\"\n",
        "\n",
        "# ============================================================\n",
        "# MASK CONVERSION (CRITICAL FIX)\n",
        "# ============================================================\n",
        "VALUE_MAP = {\n",
        "    0: 0, 100: 1, 200: 2, 300: 3, 500: 4,\n",
        "    550: 5, 700: 6, 800: 7, 7100: 8, 10000: 9\n",
        "}\n",
        "\n",
        "def convert_mask(mask):\n",
        "    arr = np.array(mask, dtype=np.uint16)\n",
        "    new = np.zeros_like(arr, dtype=np.uint8)\n",
        "    for k, v in VALUE_MAP.items():\n",
        "        new[arr == k] = v\n",
        "    return new\n",
        "\n",
        "# ============================================================\n",
        "# COLOR MAP\n",
        "# ============================================================\n",
        "COLOR_PALETTE = np.array([\n",
        "    [0, 0, 0], [34, 139, 34], [0, 255, 0], [210, 180, 140],\n",
        "    [139, 90, 43], [128, 128, 0], [139, 69, 19],\n",
        "    [128, 128, 128], [160, 82, 45], [135, 206, 235]\n",
        "], dtype=np.uint8)\n",
        "\n",
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.img_dir = os.path.join(root, \"Color_Images\")\n",
        "        self.mask_dir = os.path.join(root, \"Segmentation\")\n",
        "        self.ids = sorted(os.listdir(self.img_dir))\n",
        "        self.has_masks = os.path.exists(self.mask_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        name = self.ids[i]\n",
        "\n",
        "        img = Image.open(os.path.join(self.img_dir, name)).convert(\"RGB\")\n",
        "        img = TF.resize(img, (H, W))\n",
        "        img = TF.to_tensor(img)\n",
        "        img = TF.normalize(img, mean=[0.485,0.456,0.406],\n",
        "                                 std=[0.229,0.224,0.225])\n",
        "\n",
        "        mask = torch.zeros((H, W), dtype=torch.long)\n",
        "        if self.has_masks:\n",
        "            mp = os.path.join(self.mask_dir, name)\n",
        "            if os.path.exists(mp):\n",
        "                m = Image.open(mp)\n",
        "                m = convert_mask(m)\n",
        "                m = TF.resize(\n",
        "                    Image.fromarray(m),\n",
        "                    (H, W),\n",
        "                    interpolation=TF.InterpolationMode.NEAREST\n",
        "                )\n",
        "                mask = torch.from_numpy(np.array(m)).long()\n",
        "\n",
        "        return img, mask, name\n",
        "\n",
        "# ============================================================\n",
        "# MODEL\n",
        "# ============================================================\n",
        "class SegmentationHeadConvNeXt(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(in_c, 256, 7, padding=3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.GELU()\n",
        "        )\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(256,256,7,padding=3,groups=256),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(256,256,1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        self.cls = nn.Conv2d(256,out_c,1)\n",
        "\n",
        "    def forward(self, x, h, w):\n",
        "        b,n,c = x.shape\n",
        "        x = x.reshape(b, h//14, w//14, c).permute(0,3,1,2)\n",
        "        return self.cls(self.block(self.stem(x)))\n",
        "\n",
        "# ============================================================\n",
        "# TTA\n",
        "# ============================================================\n",
        "def apply_tta(x, k):\n",
        "    if k >= 4:\n",
        "        x = x.transpose(-1,-2)\n",
        "        k -= 4\n",
        "    return torch.rot90(x, k, dims=(-2,-1))\n",
        "\n",
        "def undo_tta(x, k):\n",
        "    x = torch.rot90(x, -(k%4), dims=(-2,-1))\n",
        "    if k >= 4:\n",
        "        x = x.transpose(-1,-2)\n",
        "    return x\n",
        "\n",
        "# ============================================================\n",
        "# METRIC\n",
        "# ============================================================\n",
        "def compute_iou(pred, gt):\n",
        "    pred = pred.view(-1)\n",
        "    gt = gt.view(-1)\n",
        "    ious = []\n",
        "    for c in range(N_CLASSES):\n",
        "        inter = ((pred==c)&(gt==c)).sum().float()\n",
        "        union = ((pred==c)|(gt==c)).sum().float()\n",
        "        if union > 0:\n",
        "            ious.append((inter/union).item())\n",
        "    return np.mean(ious) if ious else None\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "def main():\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR,\"masks\"), exist_ok=True)\n",
        "\n",
        "    backbone = torch.hub.load(\n",
        "        \"facebookresearch/dinov2\",\"dinov2_vitb14\"\n",
        "    ).to(DEVICE).eval()\n",
        "\n",
        "    models = []\n",
        "    for p in MODEL_PATHS:\n",
        "        m = SegmentationHeadConvNeXt(EMBED_DIM, N_CLASSES).to(DEVICE)\n",
        "        m.load_state_dict(torch.load(p, map_location=DEVICE))\n",
        "        m.eval()\n",
        "        models.append(m)\n",
        "\n",
        "    loader = DataLoader(TestDataset(DATA_DIR), batch_size=1)\n",
        "    all_ious = []\n",
        "\n",
        "    print(\"Running Ensemble + TTA inference...\")\n",
        "    with torch.no_grad():\n",
        "        for img, gt, name in tqdm(loader):\n",
        "            img, gt = img.to(DEVICE), gt.to(DEVICE)\n",
        "            logits_sum = torch.zeros((1,N_CLASSES,H,W), device=DEVICE)\n",
        "\n",
        "            for k in range(8):\n",
        "                aug = apply_tta(img, k)\n",
        "                h,w = aug.shape[-2:]\n",
        "                tmp = 0\n",
        "                for model in models:\n",
        "                    feat = backbone.forward_features(aug)[\"x_norm_patchtokens\"]\n",
        "                    log = model(feat, h, w)\n",
        "                    log = F.interpolate(log, (h,w), mode=\"bilinear\", align_corners=False)\n",
        "                    tmp += log\n",
        "                tmp /= len(models)\n",
        "                logits_sum += undo_tta(tmp, k)\n",
        "\n",
        "            pred = torch.argmax(logits_sum/8,1)[0]\n",
        "\n",
        "            if gt.sum() > 0:\n",
        "                iou = compute_iou(pred, gt[0])\n",
        "                if iou is not None:\n",
        "                    all_ious.append(iou)\n",
        "\n",
        "            color = COLOR_PALETTE[pred.cpu().numpy()]\n",
        "            cv2.imwrite(\n",
        "                os.path.join(OUTPUT_DIR,\"masks\",name[0]),\n",
        "                cv2.cvtColor(color, cv2.COLOR_RGB2BGR)\n",
        "            )\n",
        "\n",
        "    # =========================\n",
        "    # GRAPHS\n",
        "    # =========================\n",
        "    if all_ious:\n",
        "        plt.hist(all_ious, bins=20)\n",
        "        plt.title(\"Test IoU Distribution\")\n",
        "        plt.xlabel(\"IoU\")\n",
        "        plt.ylabel(\"Images\")\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR,\"iou_hist.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        plt.plot(np.cumsum(all_ious)/np.arange(1,len(all_ious)+1))\n",
        "        plt.title(\"Running Mean IoU\")\n",
        "        plt.xlabel(\"Images\")\n",
        "        plt.ylabel(\"Mean IoU\")\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR,\"iou_running_mean.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"\\nTEST MEAN IoU: {np.mean(all_ious):.4f}\")\n",
        "\n",
        "    shutil.make_archive(OUTPUT_DIR,\"zip\",OUTPUT_DIR)\n",
        "    print(\"DONE.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9wsnk41xdJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
